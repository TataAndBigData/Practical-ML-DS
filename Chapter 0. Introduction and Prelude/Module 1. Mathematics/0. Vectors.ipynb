{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectors\n",
    "\n",
    "### Learning Objectives:\n",
    "- [Points & Space](#Points-&-Space)\n",
    "- [Vector Length](#Vector-Length)\n",
    "- [Vector Addition & Subtraction](#Vector-Addition-&-Subtraction)\n",
    "- [Vector Multiplication](#Vector-Multiplication)\n",
    "\n",
    "\n",
    "# Points & Space\n",
    "\n",
    "__Points__ are simply a list of numbers that specifies a position in space with its __coordinates__. The number of coordinates determines the number of __dimensions__ of that space. If our space is defined by a line, all we need is one coordinate to define its position. If our space is defined by a plane, all we need are two coordinates, and if in 3-D, we would need 3 coordinates. This logic can be applied to an any N-D space, which for any dimension greater than 3 is known as a __hyperspace__.\n",
    "\n",
    "<img src=\"images/points_in_space.png\"\n",
    "     alt=\"Orthogonality\"\n",
    "     width=\"700px\"\n",
    "     height=\"700px\"/>\n",
    "\n",
    "So what are __vectors__? Vectors are a useful representation of points in any N-D space. In general, a vector is an ordered list made of __components__, each that can take a range of values to define a coordinate along a given dimension. It is ordered since each vector __entry__ refers to a coordinate along a specific dimension.\n",
    "\n",
    "In this section, we will aim to help you be able to visualize vectors, as well as carry out vector operations in Python. In Python, we can create vectors either as standard lists, or as NumPy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "x1_list = [1, 2] # 2-D vector using a standard list\n",
    "x1_numpy = np.array([1, 2]) # 2D vector using a numpy array\n",
    "\n",
    "print(x1_list)\n",
    "print(x1_numpy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To gain some intuition, let us consider a 2-D vector space with components $x_{1}$ and $x_{2}$. If we draw this in Cartesian coordinates, we can visualize this vector as an instruction in the form of an arrow to move from the origin (0,0), to the values our components take. Let us consider an example vector in this space, $\\vec{\\mathbf{v}}$. Vectors are commonly denoted in columns as follows:\n",
    "\n",
    "$$\\vec{\\mathbf{v}} = \\begin{bmatrix} 1 \\\\ 2 \\end{bmatrix}$$\n",
    "\n",
    "But can also be denoted in rows:\n",
    "\n",
    "$$\\vec{\\mathbf{v}} = \\begin{bmatrix} 1 & 2 \\end{bmatrix}$$\n",
    "\n",
    "In this case, the vector instructs us to move from (0,0) to (1,2). This is visualized in the plot below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation Code\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "x1 = [0,1]\n",
    "x2 = [0,2]\n",
    "\n",
    "\n",
    "fig = go.Figure(data=[go.Scatter(\n",
    "    x=x1, y=x2,\n",
    "    mode='markers',\n",
    "    marker=dict(size=[10,50],\n",
    "            color=[\"black\",\"orange\"])\n",
    "    )])\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Initial Vector Plot (v)\",\n",
    "    xaxis_title=\"$x_{1}$\",\n",
    "    yaxis_title=\"$x_{2}$\",\n",
    ")\n",
    "fig.add_trace(go.Scatter(x=[0, 1], y=[0, 2],marker_color=\"black\"))\n",
    "fig.update_layout(showlegend=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector Length\n",
    "Another reason why it can often be useful to visualize vectors as we have done above is that we can more intuitively understand the concept of vector __length__, also known as __magnitude__. Vector length is a measure of the size of this vector, and is completely independent of direction. If we look at the case of the 2-D vector $\\mathbf{\\vec{v}}$ shown below, with its length along each dimension also displayed. We see that it forms a right-angle triangle, meaning we can solve our problem with the Pythagoras Theorem!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "x1 = [0,1,0,1]\n",
    "x2 = [0,2,2,0]\n",
    "\n",
    "\n",
    "fig = go.Figure(data=[go.Scatter(\n",
    "    x=x1, y=x2,\n",
    "    mode='markers',\n",
    "    marker=dict(size=[50,50,25,25]),\n",
    "    marker_color=\"orange\")\n",
    "])\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Component-decomposed Vector (v)\",\n",
    "    xaxis_title=\"$x_{1}$\",\n",
    "    yaxis_title=\"$x_{2}$\",\n",
    ")\n",
    "fig.add_trace(go.Scatter(x=[0, 1], y=[0, 2],marker_color=\"black\"))\n",
    "fig.add_trace(go.Scatter(x=[0, 1], y=[0, 0],marker_color=\"black\"))\n",
    "fig.add_trace(go.Scatter(x=[0, 0], y=[0, 2],marker_color=\"black\"))\n",
    "# adding annotations\n",
    "fig.add_annotation(\n",
    "            x=0.5,\n",
    "            y=0.6,\n",
    "            text=\"$\\sqrt{x_{1}^{2} + x_{2}^{2}}$\")\n",
    "fig.add_annotation(\n",
    "            x=0.02,\n",
    "            y=0.8,\n",
    "            text=\"$x_{2}$\")\n",
    "fig.add_annotation(\n",
    "            x=0.8,\n",
    "            y=0.05,\n",
    "            text=\"$x_{1}$\")\n",
    "fig.update_annotations(dict(\n",
    "            xref=\"x\",\n",
    "            yref=\"y\",\n",
    "            showarrow=False,\n",
    "            ax=0,\n",
    "            ay=-40\n",
    "))\n",
    "\n",
    "fig.update_layout(showlegend=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, the length of a 2-D vector, which is the hypotenuse of the triangle above, is given by the equation below:\n",
    "\n",
    "$$||\\vec{\\mathbf{x}}|| = \\sqrt{x_{1}^{2} + x_{2}^{2}}$$\n",
    "\n",
    "Where $||\\vec{\\mathbf{x}}||$ denotes the length of the vector $\\vec{\\mathbf{x}}$.\n",
    "\n",
    "This means that for our example vector, $\\vec{\\mathbf{v}}$, we get $||\\vec{\\mathbf{v}}|| = \\sqrt{1^{2} + 2^{2}} = \\sqrt{5}$. So how do we extend this to higher dimensions? Well luckily, mathematicians have shown that the exact same process can be applied for any number of dimensions to obtain the length of a vector, giving us the following equations:\n",
    "\n",
    "$$\\text{3-D Case:     }||\\vec{\\mathbf{x}}|| = \\sqrt{x_{1}^{2} + x_{2}^{2} + x_{3}^{2}}$$\n",
    "$$\\text{N-D Case:     }||\\vec{\\mathbf{x}}|| = \\sqrt{\\sum_{i=1}^{N} x_{i}^{2}} $$\n",
    "($\\sum$ is the capital Greek letter sigma, and means summation)\n",
    "\n",
    "So now that we have the means, mathematically, how can we use Python to calculate the length of a vector? Below, we show you three ways: basic programming, with the Python standard library and NumPy. Note that for basic programming, a common rule of thumb is that __summation of many terms implies using iteration__, as it is a repetitive task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODING CHALLENGE\n",
    "\n",
    "import math\n",
    "\n",
    "# Example vector\n",
    "x = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "\n",
    "# Standard Python\n",
    "def vector_length(v):\n",
    "    length = 0\n",
    "    for value in v:\n",
    "        length = ##\n",
    "    length = ##\n",
    "    return length\n",
    "print(\"Vector length:\", vector_length(x))\n",
    "\n",
    "# Math module\n",
    "x_squared = [math.pow(val,2) for val in x]\n",
    "length2 = math.sqrt(sum(x_squared))\n",
    "print(\"Vector length:\", length2)\n",
    "\n",
    "# NumPy\n",
    "x = np.array(x)\n",
    "length3 = np.linalg.norm(x)\n",
    "print(\"Vector length:\", length3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector Addition & Subtraction\n",
    "Let's say now we have two vectors on the same vector space. We can now perform operations such as __vector addition__ and __vector subtraction__. What do these mean? We can better visualize these in a 2-D plane. To carry these operations out, we simply __add__ or __subtract__ components of the vectors respectively, as shown in the equations below:\n",
    "\n",
    "$$ \\vec{\\mathbf{x}}+\\vec{\\mathbf{y}} = \\begin{bmatrix} x_{1}+y_{1} \\\\ x_{2}+y_{2} \\end{bmatrix}$$\n",
    "\n",
    "$$ \\vec{\\mathbf{x}}-\\vec{\\mathbf{y}} = \\begin{bmatrix} x_{1}-y_{1} \\\\ x_{2}-y_{2} \\end{bmatrix}$$\n",
    "\n",
    "We can picture the addition of two vectors as following the \"movement\" of the first vector, then following the \"movement\" of the second vector, and seeing where you ended up! We can see this below for the example:\n",
    "\n",
    "$$\\begin{bmatrix} 3 \\\\ 3 \\end{bmatrix} + \\begin{bmatrix} 2 \\\\ 1 \\end{bmatrix} = \\begin{bmatrix} 5 \\\\ 4 \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation Code\n",
    "\n",
    "x1 = [0,3,2,5]\n",
    "x2 = [0,3,1,4]\n",
    "\n",
    "\n",
    "fig = go.Figure(data=[go.Scatter(\n",
    "    x=x1, y=x2,\n",
    "    mode='markers',\n",
    "    marker = dict(size=[10,30,30,60], \n",
    "                  color=[\"black\",\"orange\",\"orange\",\"orange\"]),\n",
    "    )\n",
    "])\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Vector Addition\",\n",
    "    xaxis_title=\"$x_{1}$\",\n",
    "    yaxis_title=\"$x_{2}$\",\n",
    ")\n",
    "fig.add_trace(go.Scatter(x=[0, 3], y=[0, 3],marker_color=\"black\"))\n",
    "fig.add_trace(go.Scatter(x=[0, 2], y=[0, 1],marker_color=\"black\"))\n",
    "fig.add_trace(go.Scatter(x=[0, 5], y=[0, 4],marker_color=\"black\"))\n",
    "# adding annotations\n",
    "fig.add_annotation(\n",
    "            x=1,\n",
    "            y=0.3,\n",
    "            text=\"$\\mathbf{y}$\")\n",
    "fig.add_annotation(\n",
    "            x=1.5,\n",
    "            y=1.8,\n",
    "            text=\"$\\mathbf{x}$\")\n",
    "fig.add_annotation(\n",
    "            x=3,\n",
    "            y=2.5,\n",
    "            text=\"$\\mathbf{x+y}$\")\n",
    "fig.update_annotations(dict(\n",
    "            xref=\"x\",\n",
    "            yref=\"y\",\n",
    "            showarrow=False,\n",
    "            ax=0,\n",
    "            ay=-40\n",
    "))\n",
    "\n",
    "fig.update_layout(showlegend=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of subtraction, we can picture the same process, but moving in the opposite direction of the vector we are subtracting by. An example of subtraction is shown below:\n",
    "\n",
    "$$\\begin{bmatrix} 5 \\\\ 4 \\end{bmatrix} - \\begin{bmatrix} 2 \\\\ 1 \\end{bmatrix} = \\begin{bmatrix} 3 \\\\ 3 \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same intuition extends to higher dimensional vector spaces. So, now that we have the intuition, we will compute  vector addition/subtraction with standard Python and with NumPy below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example vectors\n",
    "vector1 = [1,2,3,4,5,6,7,8,9,10]\n",
    "vector2 = [1,1,1,1,1,1,1,1,1,1]\n",
    "\n",
    "# CODING CHALLENGE\n",
    "def vec_add(v1,v2):\n",
    "    resultant_vector = []\n",
    "    for v1_val, v2_val in zip(v1, v2):\n",
    "        ##\n",
    "    return resultant_vector\n",
    "\n",
    "def vec_sub(v1,v2):\n",
    "    pass\n",
    "\n",
    "print(\"vector1 + vector2 =\",vec_add(vector1,vector2))\n",
    "print(\"vector1 - vector2 =\",vec_sub(vector1, vector2))\n",
    "print()\n",
    "\n",
    "\n",
    "# NumPy\n",
    "vector1 = np.array(vector1)\n",
    "vector2 = np.array(vector2)\n",
    "\n",
    "print(\"vector1 + vector2 =\", vector1 + vector2)\n",
    "print(\"vector1 - vector2 =\", vector1 - vector2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can add and subtract different vectors in vector space, as well as understand the processes visually. We can now move on to more sophisticated operations.\n",
    "\n",
    "# Vector Multiplication\n",
    "\n",
    "### Scalar Multiplication\n",
    "\n",
    "Besides addition and subtraction, other operations can be applied to vectors. One common application is known as __scalar multiplication__. A __scalar__ is a non-vector quantity, generally just a number. Scalar multiplication means that when multiplying a vector by a number (scalar), we are multiplying each value in the vector by said scalar. This is show, for the 2-D case below, given a scalar quantity a:\n",
    "$$a\\vec{\\mathbf{x}} = a\\begin{bmatrix} x_{1} \\\\ x_{2} \\end{bmatrix} = \\begin{bmatrix} ax_{1} \\\\ ax_{2} \\end{bmatrix}$$\n",
    "\n",
    "It is worth to mention that scaling a vector only changes its length, but not its direction in space, since all components are proportionally scaled. Thus, we can __normalize__ a vector, to obtain its __unit vector($\\hat{x}$)__, defined as a vector with the same direction as the original vector, but with a length/magnitude of 1. This is shown for the general 2-D case below.\n",
    "\n",
    "$$\\hat{\\mathbf{x}} = \\frac{1}{||\\vec{\\mathbf{x}}||}\\begin{bmatrix} x_{1} \\\\ x_{2} \\end{bmatrix} = \n",
    "\\begin{bmatrix} \\frac{x_{1}}{\\sqrt{x_{1}^{2} + x_{2}^{2}}} \\\\ \\frac{x_{2}}{\\sqrt{x_{1}^{2} + x_{2}^{2}}} \\end{bmatrix}$$\n",
    "\n",
    "This is more clearly with the example of the previously introduced vector, $\\mathbf{\\vec{v}}$, visualized in the diagram below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation Code\n",
    "\n",
    "\n",
    "# Vector components\n",
    "x1 = [0,0,0,1,math.sqrt(0.5),1,math.sqrt(0.5)]\n",
    "x2 = [0,1,math.sqrt(0.5),0,0,1,math.sqrt(0.5)]\n",
    "\n",
    "\n",
    "fig = go.Figure(data=[go.Scatter(\n",
    "    x=x1, y=x2,\n",
    "    mode='markers',\n",
    "    marker = dict(size=[10,50,25,50,25,50,25], \n",
    "                  color=[\"black\",\"orange\",\"orange\",\"orange\",\"orange\",\"orange\",\"orange\"]),\n",
    "    )\n",
    "])\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Normalization\",\n",
    "    xaxis_title=\"$x_{1}$\",\n",
    "    yaxis_title=\"$x_{2}$\",\n",
    ")\n",
    "fig.add_trace(go.Scatter(x=[0, 0], y=[0, 1], marker_color=\"black\"))\n",
    "fig.add_trace(go.Scatter(x=[0, 1], y=[0, 0], marker_color=\"black\"))\n",
    "fig.add_trace(go.Scatter(x=[0, 1], y=[0, 1], marker_color=\"black\"))\n",
    "# adding annotations\n",
    "fig.add_annotation(\n",
    "            x=0.9,\n",
    "            y=1,\n",
    "            text=\"$\\mathbf{v}$\")\n",
    "fig.add_annotation(\n",
    "            x=0.62,\n",
    "            y=0.72,\n",
    "            text=\"$\\mathbf{\\hat{v}}$\")\n",
    "fig.update_annotations(dict(\n",
    "            xref=\"x\",\n",
    "            yref=\"y\",\n",
    "            showarrow=False,\n",
    "            ax=0,\n",
    "            ay=-40\n",
    "))\n",
    "\n",
    "fig.update_layout(showlegend=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we show how to obtain the scalar multiple of a vector in NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining our vector and our scalar\n",
    "a = 3\n",
    "vector = np.array([1,2,3,4,5,6,7,8,9,10])\n",
    "\n",
    "scaled_vector = a*vector\n",
    "print(\"The scalar product is\",scaled_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector Inner-product\n",
    "\n",
    "Another crucial form of vector multiplication is what is known as the __inner product__, also known as the __dot product__. It is defined as the product of the projection of the first vector onto the second vector and the magnitude of the second vector. There are two ways of calculating the inner product of two vectors. For any two vectors of equal dimension, $\\mathbf{\\vec{x}}$ and $\\mathbf{\\vec{y}}$, the algebraic definition is given by:\n",
    "\n",
    "$$ \\text{2-D Case: } \\langle \\mathbf{\\vec{x}},\\mathbf{\\vec{y}} \\rangle =\\mathbf{\\vec{x}}\\cdot \\mathbf{\\vec{y}} = x_{1}y_{1} + x_{2}y_{2} $$\n",
    "$$ \\text{N-D Case: } \\langle \\mathbf{\\vec{x}},\\mathbf{\\vec{y}} \\rangle =\\mathbf{\\vec{x}}\\cdot \\mathbf{\\vec{y}} = \\sum_{i=1}^{N}x_{i}y_{i} $$\n",
    "\n",
    "From this definition, we can see that since components in the same dimension are multiplied together. If they are both large and positive, the product will also be large. If one is large and one is small, the product will not be as large. If the values have opposite signs, the product will be negative. Hence, we can already develop an intuition on the result of a dot-product:\n",
    "- The more two vectors are in the _same_ direction, the larger their inner product will be\n",
    "- The more two vectors are in _opposite_ direction, the more negative their inner product will be\n",
    "\n",
    "This means that the inner product is a measure of how two vectors allign, proportional to their respective magnitudes. Some vectors, however, have no possible alignment, and are known as __orthogonal vectors__. Since there is no alignment, the inner-product of orthogonal vectors is always 0, no matter their respective magnitudes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation Code\n",
    "\n",
    "# Vector components\n",
    "x1 = [0,0,1]\n",
    "x2 = [0,1,0]\n",
    "\n",
    "fig = go.Figure(data=[go.Scatter(\n",
    "    x=x1, y=x2,\n",
    "    mode='markers',\n",
    "    marker = dict(size=[10,50,50], \n",
    "                  color=[\"black\",\"orange\",\"orange\"]),\n",
    "    )\n",
    "])\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Orthogonal Vectors\",\n",
    "    xaxis_title=\"$x_{1}$\",\n",
    "    yaxis_title=\"$x_{2}$\",\n",
    ")\n",
    "fig.add_trace(go.Scatter(x=[0, 1], y=[0, 0], marker_color=\"black\"))\n",
    "fig.add_trace(go.Scatter(x=[0, 0], y=[0, 1], marker_color=\"black\"))\n",
    "\n",
    "fig.update_layout(showlegend=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What exactly does it mean to have __orthogonal vectors__? Since the inner-product is 0, the projection of one vector onto the other is zero. Consider a traveller crossing a desert who follows a map to reach the nearest town by walking south-east. After having learned a bit about vectors, you will already be able to tell that travelling south-east can be broken down into a \"south\" component and an \"east\" component, so the projection of how much the traveller has walked in the \"south\" direction is how far south that traveller has gone. \n",
    "\n",
    "But what if he realises that he does not need to go east, and travels strictly in a \"south\" direction. How much will he have travelled in the \"east\" or \"west\" direction? Nothing! He can travel forever in the \"south\" direction, but that will never contribute to his distance to the \"east\", since \"east\" and \"south\" are orthogonal!\n",
    "\n",
    "<img src=\"images/orthogonality.png\"\n",
    "     alt=\"Orthogonality\"\n",
    "     width=\"600px\"\n",
    "     height=\"600px\"/>\n",
    "\n",
    "This intution still applies to any N-D vector! If a pair/set of orthogonal vectors all also have unit length, they are further classified as __orthonormal vectors__. We will now see how to compute, in both Standard Python and NumPy, how to compute a vector inner product:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODING CHALLENGE\n",
    "\n",
    "# Defining our vectors\n",
    "vector1 = [1,2,3,4,5,6,7,8,9,10]\n",
    "orthogonal_vector = [-2,-2,-2,-2,0,0,0,0,0,2]\n",
    "\n",
    "# Standard Python\n",
    "def inner_product(v1, v2): # function that computes algebraic inner product of two vectors\n",
    "    product = 0\n",
    "    for value1, value2 in zip(v1,v2):\n",
    "        product += ##\n",
    "    return product\n",
    "# Displaying our results\n",
    "print(\"Results with standard Python\")\n",
    "print(\"Inner-product:\",inner_product(vector1,orthogonal_vector))\n",
    "print()\n",
    "\n",
    "\n",
    "# NumPy \n",
    "print(\"Results with NumPy\")\n",
    "print(\"Inner-product:\",np.dot(vector1,orthogonal_vector))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Element-wise (Hadamard) Product\n",
    "While less commonly used with vectors, another form of vector multiplication is __element-wise multiplication__, also known as __Hadamard Multiplication__. Applying this operation to two vectors returns another vector of the same dimension, where each entry is the product of the respective entries of the input vectors, as shown below for an N-D vector:\n",
    "\n",
    "$$\\vec{\\mathbf{x}} \\circ \\vec{\\mathbf{y}} = \\begin{bmatrix} x_{1}y_{1} \\\\ x_{2}y_{2}\\\\ \\vdots \\\\x_{N}y_{N} \\end{bmatrix} $$\n",
    "\n",
    "Below we show how to compute the element-wise product of two vectors in standard Python and NumPy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialising our vectors\n",
    "vector1 = [1,2,3,4,5,6,7,8,9,10]\n",
    "vector2 = [1,2,3,4,5,6,7,8,9,10]\n",
    "\n",
    "\n",
    "# Standard Python\n",
    "def hadamard_product(v1, v2):\n",
    "    product = []\n",
    "    for value1, value2 in zip(v1, v2):\n",
    "        product.append(value1*value2)\n",
    "    return product\n",
    "print(\"Standard Python element-wise product:\", hadamard_product(vector1, vector2))\n",
    "\n",
    "\n",
    "# NumPy\n",
    "print(\"NumPy element-wise product:\", np.multiply(vector1, vector2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congratulations!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
